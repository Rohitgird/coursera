# Big Data Basics 

### Characteristics of Big Data<br>
####The Big Vs of Big Data<br>

- **Volume**: Refers to the vast amounts of data that is generated every second, minute, hour and day. 
    - Digital data will grow by a factor of 44, to around 35.2 ZB. 
    - There are some challenges in massive volume, which include storage, data acquisition, retrieval, distribution and processing. 

- **Velocity**: _(Speed)_ Refers to the speed at which data is being generated and the pace at which data moves from one point to the next.
    - `Velocity = Speed - (Change of X / Change of T)`
    - Batch Processing: Collect Data, Clean, Feed in Chunks, Wait, Act.
    - Realtime Processing: Instantly capture streaming data, feed realtime, process real-time, act.
    
- **Variety**: _(Complexity)_ Increasing forms that data can come in such as text, images, voice and geospatial data, etc. 
    - Can be structured in several dimensions
        - **Structural Variety:** Difference in the representation of the data. Formats and models. (e.g, an EKG signal is very different from a news paper article)
        - **Media Variety:** Medium in which data gets delivered. (e.g, Audio speech vs transcripts)
        - **Semantic Variety:** How to interpret and operate on data. (e.g, age can be a number or terms like infant, juvenile, adult, etc.)

> Some additional _Vs_ to remember
 
- **Veracity:** _(Quality)_ Refers to the biases, noise and abnormality in the data.
    - Data has no value if it's not accurate. ( Junk in = Junk out )
    - **Data Providence:** What information did data go through up until the moment it was used for an estimate?
    - The growing torrents of big data pushes it for fast solutions. This creates challenges of data quality, what has been collected, where it came from and how it was analyzed.

- **Valence:** _(Connectedness)_ Connectedness of big data in the form of graphs.
    - The more connected the data is, the higher the valence. 
    - Valence challenges include more complex data exploration algorithms, modeling and prediction of valence changes, gorup event detections, emergent behavior analysis.

- **Value:** How does big data benefit you and your organization. Turning data into opportunities.

---
### Data Science, Getting Value out of Big Data

Data science can be thought of as a basis for empirical research where data is used to induce information for observations.
Data scientist are people who have passion for data, can relate problems to analytics, care about engineering solutions to solve problems, exhibit curiosity, and communicate well. 
 
#### Skills related to Data Science
- **Math and Statistics**
    - Machine Learning, Statistical modeling, experiment design, Bayesian inference
    - Supervised learning: Decision trees, random forest, logistic regression
    - Unsupervised learning: Clustering, dimensionality reduction.
    - Optimization: Gradient descent and variants.
- **Programming & Databases**
    - Computer science fundamentals, scripting languages (e.g python), statistical computing packages (e.g, R), databases (e.g, SQL, MongoDB)
    - Relational algebra
    - Parallel processing, distributed computing
    - Hadoop, Hive, Pig, MapReduce concepts
- **Domain Knowledge & Soft Skills**
    - Passionate about the business, curious about the data
    - Influence without authority. 
    - Hacker mindset, problem solving.
    - Strategic, proactive, creative, innovative & collaborative.
- **Communication & Visualization**
    - Able to engage with senior management
    - Storytelling skills, translate data-driven insights into decisions and actions.
    - Visual art design, D3.js, Tableau, Flare
    
#### Five Components of Data Science
- **People:** Refers to the data science team. (Engineers, Business)
- **Purpose:** Refers to the challenges defined by your strategy. 
- **Process:** Define a process to collaborite and communicate around. 
    - Big Data Engineering, Computation Big Data Science (Advanced Analytics)
    - Acquire Data --> Prepare Data --> Analyze Data --> Generate Reports --> Act
- **Platforms:** Hadoop Framework, Scalability, Infrastructure, etc.
- **Progammability:** Should be programmable through reusable interfaces.
 
